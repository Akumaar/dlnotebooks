{"paragraphs":[{"text":"%md\nThis notebook builds a simple spam classifier using the XGBoost built-in algorithm in Amazon SageMaker.","user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>This notebook builds a simple spam classifier using the XGBoost built-in algorithm in Amazon SageMaker.</p>\n"}]},"apps":[],"jobName":"paragraph_1525681076857_-1223464450","id":"20171212-103058_161186422","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:37:24+0000","dateFinished":"2018-05-07T13:37:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1117"},{"title":"Import Spark classes","text":"import org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.feature.HashingTF\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport com.amazonaws.services.sagemaker.sparksdk.IAMRole\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms.KMeansSageMakerEstimator","user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.mllib.feature.HashingTF\nimport org.apache.spark.mllib.regression.LabeledPoint\nimport com.amazonaws.services.sagemaker.sparksdk.IAMRole\nimport com.amazonaws.services.sagemaker.sparksdk.algorithms.KMeansSageMakerEstimator\n"}]},"apps":[],"jobName":"paragraph_1525681076858_-1222310204","id":"20171103-192637_633852683","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:37:24+0000","dateFinished":"2018-05-07T13:37:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1118"},{"title":"Ingest sentences","text":"// Load 2 types of emails from text files: spam and ham (non-spam).\n// Each line has text from one email.\n\n// Convert to lower case, remove punctuation and numbers, trim whitespace\n// This adds 0.6% accurary!\n\nval spam = sc.textFile(\"s3://jsimon-public/spam\")\n    .map(l => l.toLowerCase())\n    .map(l => l.replaceAll(\"[^ a-z]\", \"\"))\n    .map(l => l.trim())\n    \nval ham = sc.textFile(\"s3://jsimon-public/ham\")\n    .map(l => l.toLowerCase())\n    .map(l => l.replaceAll(\"[^ a-z]\", \"\"))\n    .map(l => l.trim())\n    \nspam.take(5)","user":"anonymous","dateUpdated":"2018-05-07T13:49:00+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"spam: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2251] at map at <console>:156\nham: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2256] at map at <console>:153\nres661: Array[String] = Array(you have  new message please call, urgent please call  from landline your abta complimentary  tenerife holiday or  cash await collection sae tcs box  cwwx ppm, dear xxxxxxx uve been invited to xchat this is our final attempt to contact u txt chat to  pmsgrcvdhgsuitelandsrowwjhl ldn yrs, u  have a secret admirer who is looking  make contact with ufind out who they rreveal who thinks ur so specialcall on, congrats  mobile g videophones r yours call  now videochat wid ur mates play java games dload polyh music noline rentl bx ip we pm)\n"}]},"apps":[],"jobName":"paragraph_1525681076858_-1222310204","id":"20171103-192703_618600372","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:37:24+0000","dateFinished":"2018-05-07T13:37:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1119"},{"title":"Map sentences to features","text":"// Create a HashingTF instance to map email text to vectors of features.\nval tf = new HashingTF(numFeatures = 200)\n// Each email is split into words, and each word is mapped to one feature.\nval spamFeatures = spam.map(email => tf.transform(email.split(\" \")))\nval hamFeatures = ham.map(email => tf.transform(email.split(\" \")))\n\n// Display features for a spam sample\nspamFeatures.take(1)\n// Display features for a ham sample\nhamFeatures.take(1)","user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"tf: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@5c03d5b4\nspamFeatures: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[2257] at map at <console>:152\nhamFeatures: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[2258] at map at <console>:151\nres666: Array[org.apache.spark.mllib.linalg.Vector] = Array((200,[25,41,99,146,172,181],[2.0,1.0,1.0,1.0,1.0,1.0]))\nres668: Array[org.apache.spark.mllib.linalg.Vector] = Array((200,[15,83,96,188],[1.0,1.0,2.0,2.0]))\n"}]},"apps":[],"jobName":"paragraph_1525681076858_-1222310204","id":"20171103-193110_69215172","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:37:25+0000","dateFinished":"2018-05-07T13:37:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1120"},{"title":"Label features","text":"// Create LabeledPoint datasets for positive (spam) and negative (ham) examples.\nval positiveExamples = spamFeatures.map(features => LabeledPoint(1, features))\nval negativeExamples = hamFeatures.map(features => LabeledPoint(0, features))\n\n// Display label for a spam sample\npositiveExamples.take(1)\n// Display label for a ham sample\nnegativeExamples.take(1)","user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"positiveExamples: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2259] at map at <console>:150\nnegativeExamples: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2260] at map at <console>:149\nres672: Array[org.apache.spark.mllib.regression.LabeledPoint] = Array((1.0,(200,[25,41,99,146,172,181],[2.0,1.0,1.0,1.0,1.0,1.0])))\nres674: Array[org.apache.spark.mllib.regression.LabeledPoint] = Array((0.0,(200,[15,83,96,188],[1.0,1.0,2.0,2.0])))\n"}]},"apps":[],"jobName":"paragraph_1525681076858_-1222310204","id":"20171103-193056_931431977","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:37:26+0000","dateFinished":"2018-05-07T13:37:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1121"},{"title":"Split data set for training and test","text":"val data = positiveExamples.union(negativeExamples)\n\n// Split the data set 80/20\nval Array(trainingData, testData) = data.randomSplit(Array(0.8, 0.2))","user":"anonymous","dateUpdated":"2018-05-07T14:13:15+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = UnionRDD[2301] at union at <console>:152\ntrainingData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2302] at randomSplit at <console>:155\ntestData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[2303] at randomSplit at <console>:155\n"}]},"apps":[],"jobName":"paragraph_1525681076858_-1222310204","id":"20171103-193130_50274934","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T14:13:15+0000","dateFinished":"2018-05-07T14:13:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1122"},{"title":"Convert training data to the required format","text":"// The XGBoost built-in algo requires a libsvm-formatted DataFrame\nval trainingData_libsvm = MLUtils.convertVectorColumnsToML(trainingData.toDF)\ntrainingData_libsvm.show(5)","user":"anonymous","dateUpdated":"2018-05-07T13:37:31+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainingData_libsvm: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  1.0|(200,[25,41,99,14...|\n|  1.0|(200,[30,41,63,91...|\n|  1.0|(200,[17,19,42,48...|\n|  1.0|(200,[17,19,20,25...|\n|  1.0|(200,[13,20,34,36...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525682899535_-1284819603","id":"20180507-084819_415824983","dateCreated":"2018-05-07T08:48:19+0000","dateStarted":"2018-05-07T13:37:31+0000","dateFinished":"2018-05-07T13:37:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1123"},{"title":"Configure XGBoost training job","text":"val roleArn = \"arn:aws:iam::ACCOUNT_NUMBER:role/ROLE_NAME\"\n\nval xgboost_estimator = new XGBoostSageMakerEstimator(\n    trainingInstanceType=\"ml.m4.xlarge\", trainingInstanceCount=1,\n    endpointInstanceType=\"ml.m4.xlarge\", endpointInitialInstanceCount=1, \n    sagemakerRole=IAMRole(roleArn))\n\nxgboost_estimator.setObjective(\"multi:softmax\")\nxgboost_estimator.setNumRound(25)\nxgboost_estimator.setNumClasses(2)  // Binary classifier","user":"anonymous","dateUpdated":"2018-05-07T13:37:31+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"roleArn: String = arn:aws:iam::ACCOUNT_NUMBER:role/ROLE_NAME\nxgboost_estimator: com.amazonaws.services.sagemaker.sparksdk.algorithms.XGBoostSageMakerEstimator = sagemaker_6f534e6b1519\nres682: xgboost_estimator.type = sagemaker_6f534e6b1519\nres683: xgboost_estimator.type = sagemaker_6f534e6b1519\nres684: xgboost_estimator.type = sagemaker_6f534e6b1519\n"}]},"apps":[],"jobName":"paragraph_1525682199615_-1096860160","id":"20180507-083639_1212267512","dateCreated":"2018-05-07T08:36:39+0000","dateStarted":"2018-05-07T13:37:31+0000","dateFinished":"2018-05-07T13:37:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1124"},{"title":"Train model on SageMaker","text":"val xgboost_model = xgboost_estimator.fit(trainingData_libsvm)","user":"anonymous","dateUpdated":"2018-05-07T13:37:32+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525682661538_188446877","id":"20180507-084421_1148037993","dateCreated":"2018-05-07T08:44:21+0000","dateStarted":"2018-05-07T13:37:32+0000","dateFinished":"2018-05-07T13:48:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1125","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"xgboost_model: com.amazonaws.services.sagemaker.sparksdk.SageMakerModel = sagemaker_6f534e6b1519\n"}]}},{"title":"Convert test data to the required format","text":"// The XGBoost built-in algo requires a libsvm-formatted DataFrame\nval testData_libsvm = MLUtils.convertVectorColumnsToML(testData.toDF)\ntestData_libsvm.show(5)","user":"anonymous","dateUpdated":"2018-05-07T13:37:33+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525683630640_-1284212093","id":"20180507-090030_630215816","dateCreated":"2018-05-07T09:00:30+0000","dateStarted":"2018-05-07T13:37:33+0000","dateFinished":"2018-05-07T13:48:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1126","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"testData_libsvm: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: double, features: vector]\n+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  1.0|(200,[1,29,37,48,...|\n|  1.0|(200,[8,36,47,49,...|\n|  1.0|(200,[13,16,25,26...|\n|  1.0|(200,[24,36,40,52...|\n|  1.0|(200,[30,73,87,91...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"}]}},{"title":"Predict test set","text":"val transformedData = xgboost_model.transform(testData_libsvm)\ntransformedData.show(10)","user":"anonymous","dateUpdated":"2018-05-07T13:48:13+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"transformedData: org.apache.spark.sql.DataFrame = [label: double, features: vector ... 1 more field]\n+-----+--------------------+----------+\n|label|            features|prediction|\n+-----+--------------------+----------+\n|  1.0|(200,[1,29,37,48,...|       1.0|\n|  1.0|(200,[8,36,47,49,...|       1.0|\n|  1.0|(200,[13,16,25,26...|       1.0|\n|  1.0|(200,[24,36,40,52...|       1.0|\n|  1.0|(200,[30,73,87,91...|       1.0|\n|  1.0|(200,[2,13,25,61,...|       1.0|\n|  1.0|(200,[25,33,63,66...|       0.0|\n|  1.0|(200,[9,10,19,43,...|       1.0|\n|  1.0|(200,[3,25,31,36,...|       1.0|\n|  1.0|(200,[14,19,31,36...|       1.0|\n+-----+--------------------+----------+\nonly showing top 10 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525683588755_470196919","id":"20180507-085948_1671983812","dateCreated":"2018-05-07T08:59:48+0000","dateStarted":"2018-05-07T13:48:13+0000","dateFinished":"2018-05-07T13:48:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1127"},{"title":"Measure accuracy of model","text":"val accuracy = 1.0 * transformedData.filter($\"label\"=== $\"prediction\").count / transformedData.count()","user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"accuracy: Double = 0.9623467600700525\n"}]},"apps":[],"jobName":"paragraph_1525681076859_-1222694953","id":"20171103-193159_224907724","dateCreated":"2018-05-07T08:17:56+0000","dateStarted":"2018-05-07T13:48:14+0000","dateFinished":"2018-05-07T13:48:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1128"},{"user":"anonymous","dateUpdated":"2018-05-07T13:37:24+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525681076860_-1224618697","id":"20171104-160307_946818638","dateCreated":"2018-05-07T08:17:56+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:1129"}],"name":"Spam classifier with SageMaker","id":"2DE8X597W","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}
